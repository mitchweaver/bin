#!/bin/dash
#
# http://github.com/mitchweaver/bin
#
# play youtube subscriptions with dmenu, mpv, and youtube-dl
#

# create dir, empty if already exists
dir=/tmp/yt
opml_file=${HOME}/.youtube_subs.opml
mkdir /tmp/yt 2> /dev/null
rm /tmp/yt/* 2> /dev/null

# parse the terrible xml that is our opml subscription file
# dump the channel names and their rss links to corresponding files
cat $opml_file | tr '><' '\n' | \
    sed -e 's/" title.*.xmlUrl="/\n/g' \
        -e 's/outline text="//g' \
        -e 's/" \///g' \
        -e '/^$/d' \
        -e '1,7d' |
    head -n -3 | \
    while IFS='' read -r line || [ -n "$line" ] ; do
        if echo $line | grep http > /dev/null ; then
            echo "$line" >> $dir/rss_links
        else
            echo "$line" >> $dir/chan_names
        fi
    done

# takes a channel rss feed link and creates files of titles, urls, dates, and channels
get_vids() {
    curl -s `cat /tmp/yt/rss_links | sed -n "$1p"` > $dir/dl$1 || return

    date=`cat $dir/dl$1 | grep 'published' | sed -E -e 's/( )*<\/?published>//g' -e 's/\+.*//g' -e '1d'`
    if ! echo "$date" | grep `date "+%Y"` > /dev/null ; then
        return
    else
        echo "$date" >> $dir/vid_dates$1
    fi

    cat $dir/dl$1 | grep 'media:title' | sed -E 's/( )*<\/?media:title>//g' >> $dir/vid_titles$1
    cat $dir/dl$1 | grep 'media:content url' | sed -E -e 's/( )*<\/?media:content url="//g' -e 's/" type.*//g' >> $dir/vid_urls$1

    for i in $(seq 1 $(echo "$date" | wc -l)) ; do
        cat $dir/chan_names | sed -n "$1p" >> $dir/vid_chans$1
    done

    # cleanup
    rm $dir/dl$1
}

echo "1. fetching ..."
count=0
for i in `seq 1 $(cat $dir/rss_links | wc -l)` ; do
    get_vids $i &
    count=$(( $count + 1 ))
done

# wait for background processes to finish
wait

# concantenate all subfiles into collated files
for i in `seq 1 $(cat $dir/rss_links | wc -l)` ; do
    for file in vid_dates vid_chans vid_titles vid_urls ; do
        if [ -f $dir/"$file"$i ] ; then
            cat $dir/"$file"$i >> $dir/$file
            rm $dir/"$file"$i
        fi
    done
done

# concantenates files side by side, line by line
# note: paste can't use multi-char delimiters, and it cant do full unicode
#       using '`' as a junk character here so it can later be split into
#       my desired delimiter with a sed replace
echo "2. concatenating ..."
paste -d '`' $dir/vid_dates $dir/vid_chans $dir/vid_titles $dir/vid_urls > $dir/concat

# now that we have all our information in the file, since we gathered them
# channel by channel we want to collate them based on date
echo "3. sorting ..."
sort -r $dir/concat -o $dir/concat

# send through our discovered info, nicely formatted, to dmenu
choice=`cat $dir/concat  | awk -F '\`' '{print $2 " - " $3}' | menu -p 'YouTube:' | sed 's/ - /\`/'`

# read in the final concatenated file, and check for what our dmenu choice was
# grab the link, and run it with mpv
while IFS='' read -r line || [ -n "$line" ] ; do
        if echo $line | grep "$choice" > /dev/null ; then
            url=`echo $line | grep -oE 'http.*'`
        fi
done < /tmp/yt/concat

[ -n "$url" ] && mpv "$url"
